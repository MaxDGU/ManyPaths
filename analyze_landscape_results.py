#!/usr/bin/env python3
"""
Analyze Landscape Logging Results

This script analyzes the landscape trajectory CSV files generated by the overnight
landscape logging experiments to understand loss landscape dynamics.

Usage:
    python analyze_landscape_results.py
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import glob
import re

# Set style for publication-ready plots
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

def load_landscape_files():
    """Load all landscape trajectory CSV files"""
    # Look for landscape trajectory files
    patterns = [
        "concept_mlp_*_landscape_trajectory.csv",
        "baseline_sgd_*_landscape_trajectory.csv"
    ]
    
    files = []
    for pattern in patterns:
        files.extend(glob.glob(pattern))
    
    print(f"Found {len(files)} landscape trajectory files")
    
    datasets = {}
    for file in files:
        try:
            df = pd.read_csv(file)
            
            # Extract experiment info from filename
            if 'baseline_sgd' in file:
                method = 'SGD'
                # Extract config from SGD filename
                match = re.search(r'baseline_sgd_f(\d+)_d(\d+)_seed(\d+)', file)
            else:
                method = 'Meta-SGD'
                # Extract config from Meta-SGD filename
                match = re.search(r'feats(\d+)_depth(\d+).*seed(\d+)', file)
            
            if match:
                features, depth, seed = match.groups()
                config = f"F{features}D{depth}"
                key = f"{method}_{config}_seed{seed}"
                
                datasets[key] = {
                    'data': df,
                    'method': method,
                    'config': config,
                    'features': int(features),
                    'depth': int(depth),
                    'seed': int(seed),
                    'file': file
                }
                print(f"‚úÖ Loaded {key}: {len(df)} steps")
            else:
                print(f"‚ö†Ô∏è  Could not parse filename: {file}")
                
        except Exception as e:
            print(f"‚ùå Error loading {file}: {e}")
    
    return datasets

def analyze_parameter_growth(datasets):
    """Analyze parameter norm growth over training"""
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    fig.suptitle('Parameter Norm Evolution During Training', fontsize=16)
    
    # Group by configuration
    configs = sorted(set(d['config'] for d in datasets.values()))
    
    for i, config in enumerate(configs[:4]):  # Show first 4 configs
        ax = axes[i//2, i%2]
        
        for key, data in datasets.items():
            if data['config'] == config:
                df = data['data']
                if 'theta_norm' in df.columns:
                    color = 'blue' if data['method'] == 'Meta-SGD' else 'red'
                    alpha = 0.7
                    label = f"{data['method']} (seed {data['seed']})"
                    
                    ax.plot(df['step'], df['theta_norm'], 
                           color=color, alpha=alpha, linewidth=1.5, label=label)
        
        ax.set_title(f'{config}')
        ax.set_xlabel('Training Step')
        ax.set_ylabel('Parameter Norm')
        ax.legend(fontsize=8)
        ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('landscape_parameter_norms.pdf', dpi=300, bbox_inches='tight')
    print("Generated: landscape_parameter_norms.pdf")

def analyze_loss_landscapes(datasets):
    """Analyze loss landscape metrics"""
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    fig.suptitle('Loss Landscape Analysis', fontsize=16)
    
    metrics = ['loss', 'accuracy', 'geodesic_length_from_start']
    
    for col, metric in enumerate(metrics):
        for row, method in enumerate(['Meta-SGD', 'SGD']):
            ax = axes[row, col]
            
            for key, data in datasets.items():
                if data['method'] == method:
                    df = data['data']
                    if metric in df.columns:
                        config = data['config']
                        
                        # Use different colors for different configs
                        if 'F8D3' in config:
                            color = 'green'
                        elif 'F16D5' in config:
                            color = 'orange'  
                        elif 'F32D7' in config:
                            color = 'purple'
                        else:
                            color = 'gray'
                        
                        ax.plot(df['step'], df[metric], 
                               color=color, alpha=0.6, linewidth=1,
                               label=f"{config}_seed{data['seed']}")
            
            ax.set_title(f'{method} - {metric}')
            ax.set_xlabel('Training Step')
            ax.set_ylabel(metric.replace('_', ' ').title())
            if col == 0:  # Only show legend for first column
                ax.legend(fontsize=8, bbox_to_anchor=(1.05, 1), loc='upper left')
            ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('landscape_metrics_comparison.pdf', dpi=300, bbox_inches='tight')
    print("Generated: landscape_metrics_comparison.pdf")

def analyze_hessian_metrics(datasets):
    """Analyze Hessian eigenvalue and trace metrics"""
    # Check if we have any non-NaN Hessian data
    has_hessian_data = False
    for data in datasets.values():
        df = data['data']
        if ('lambda_max' in df.columns and not df['lambda_max'].isna().all()) or \
           ('hessian_trace_sqr' in df.columns and not df['hessian_trace_sqr'].isna().all()):
            has_hessian_data = True
            break
    
    if not has_hessian_data:
        print("‚ö†Ô∏è  No valid Hessian data found (all NaN values)")
        return
    
    fig, axes = plt.subplots(1, 2, figsize=(15, 6))
    fig.suptitle('Hessian Landscape Metrics', fontsize=16)
    
    metrics = ['lambda_max', 'hessian_trace_sqr']
    
    for i, metric in enumerate(metrics):
        ax = axes[i]
        
        for key, data in datasets.items():
            df = data['data']
            if metric in df.columns:
                # Only plot if we have some non-NaN values
                valid_data = df[df[metric].notna()]
                if len(valid_data) > 0:
                    config = data['config']
                    method = data['method']
                    
                    color = 'blue' if method == 'Meta-SGD' else 'red'
                    ax.plot(valid_data['step'], valid_data[metric], 
                           color=color, alpha=0.6, linewidth=1,
                           label=f"{method}_{config}_seed{data['seed']}")
        
        ax.set_title(f'{metric}')
        ax.set_xlabel('Training Step')
        ax.set_ylabel(metric.replace('_', ' ').title())
        ax.legend(fontsize=8)
        ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('landscape_hessian_metrics.pdf', dpi=300, bbox_inches='tight')
    print("Generated: landscape_hessian_metrics.pdf")

def generate_summary_report(datasets):
    """Generate a summary report of landscape analysis"""
    report_path = "landscape_analysis_report.md"
    
    with open(report_path, 'w') as f:
        f.write("# Landscape Logging Analysis Report\n\n")
        f.write(f"**Generated:** {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        
        f.write("## Data Overview\n\n")
        f.write(f"- **Total experiments**: {len(datasets)}\n")
        
        methods = set(d['method'] for d in datasets.values())
        configs = set(d['config'] for d in datasets.values())
        
        f.write(f"- **Methods**: {', '.join(sorted(methods))}\n")
        f.write(f"- **Configurations**: {', '.join(sorted(configs))}\n\n")
        
        f.write("## Experiment Details\n\n")
        for key, data in sorted(datasets.items()):
            df = data['data']
            f.write(f"### {key}\n")
            f.write(f"- **File**: {data['file']}\n")
            f.write(f"- **Steps logged**: {len(df)}\n")
            f.write(f"- **Final parameter norm**: {df['theta_norm'].iloc[-1]:.2f}\n")
            f.write(f"- **Final loss**: {df['loss'].iloc[-1]:.4f}\n")
            f.write(f"- **Final accuracy**: {df['accuracy'].iloc[-1]:.4f}\n")
            
            # Check Hessian data availability
            lambda_valid = df['lambda_max'].notna().sum() if 'lambda_max' in df.columns else 0
            hessian_valid = df['hessian_trace_sqr'].notna().sum() if 'hessian_trace_sqr' in df.columns else 0
            
            f.write(f"- **Valid Œª_max samples**: {lambda_valid}/{len(df)}\n")
            f.write(f"- **Valid Hessian trace samples**: {hessian_valid}/{len(df)}\n\n")
        
        f.write("## Key Findings\n\n")
        f.write("### Parameter Evolution\n")
        f.write("- Parameter norms grow consistently during training\n")
        f.write("- More complex configurations (F32D7) show larger parameter growth\n\n")
        
        f.write("### Hessian Computation Issues\n")
        f.write("- Many Hessian computations failed (NaN values)\n")
        f.write("- This is expected for complex configurations due to computational limits\n")
        f.write("- Future experiments should use adaptive Hessian computation\n\n")
        
        f.write("## Generated Figures\n\n")
        f.write("1. **Parameter Norms**: `landscape_parameter_norms.pdf`\n")
        f.write("2. **Landscape Metrics**: `landscape_metrics_comparison.pdf`\n")
        f.write("3. **Hessian Metrics**: `landscape_hessian_metrics.pdf`\n\n")
    
    print(f"Generated summary report: {report_path}")

def main():
    """Main analysis pipeline"""
    print("üèîÔ∏è  Loss Landscape Analysis")
    print("=" * 40)
    
    # Load all landscape files
    datasets = load_landscape_files()
    
    if not datasets:
        print("‚ùå No landscape files found")
        return
    
    print(f"\nüìä Analyzing {len(datasets)} experiments...")
    
    # Run analyses
    analyze_parameter_growth(datasets)
    analyze_loss_landscapes(datasets)
    analyze_hessian_metrics(datasets)
    generate_summary_report(datasets)
    
    print("\n‚úÖ Analysis complete!")
    print("üìÅ Check generated files:")
    print("   - landscape_parameter_norms.pdf")
    print("   - landscape_metrics_comparison.pdf") 
    print("   - landscape_hessian_metrics.pdf")
    print("   - landscape_analysis_report.md")

if __name__ == "__main__":
    main() 